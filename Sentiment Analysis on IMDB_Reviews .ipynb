{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB Movie Reviews - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import LSTM,Activation,Dense,Dropout,Input,Embedding\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD IMDB DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Asus\\\\Downloads'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "0    A very, very, very slow-moving, aimless movie ...          0\n",
       "1    Not sure who was more lost - the flat characte...          0\n",
       "2    Attempting artiness with black & white and cle...          0\n",
       "3         Very little music or anything to speak of.            0\n",
       "4    The best scene in the movie was when Gerardo i...          1\n",
       "..                                                 ...        ...\n",
       "743  I just got bored watching Jessice Lange take h...          0\n",
       "744  Unfortunately, any virtue in this film's produ...          0\n",
       "745                   In a word, it is embarrassing.            0\n",
       "746                               Exceptionally bad!            0\n",
       "747  All in all its an insult to one's intelligence...          0\n",
       "\n",
       "[748 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb=pd.read_csv('C:/Users/Asus/Downloads/Data/imdb_labelled.txt',sep='\\t',header=None,names=['review','sentiment'])\n",
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA SPLITTING INTO TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train,imdb_test=train_test_split(imdb,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>There still are good actors around!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Oh yeah, and the storyline was pathetic too.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>My 8/10 score is mostly for the plot.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>This review is long overdue, since I consider ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>I can't see how this movie can be an inspirati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>) a happy, wonderful, feel good ending!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>I saw it as a child on TV back in 1973, when i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Shot in the Southern California desert using h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Avoid, avoid, avoid!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>I am so pleased to know such a modern day geni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "456              There still are good actors around!            1\n",
       "231     Oh yeah, and the storyline was pathetic too.            0\n",
       "250            My 8/10 score is mostly for the plot.            1\n",
       "16   This review is long overdue, since I consider ...          1\n",
       "490  I can't see how this movie can be an inspirati...          0\n",
       "..                                                 ...        ...\n",
       "534          ) a happy, wonderful, feel good ending!            1\n",
       "584  I saw it as a child on TV back in 1973, when i...          1\n",
       "493  Shot in the Southern California desert using h...          1\n",
       "527                             Avoid, avoid, avoid!            0\n",
       "168  I am so pleased to know such a modern day geni...          1\n",
       "\n",
       "[598 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>I'd advise anyone to go and see it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>However, this didn't make up for the fact that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>Avoid at ALL costs!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>This movie is so awesome!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Though The Wind and the Lion is told largely t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Even the squibs look awful.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>Meredith M was better than all right.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>One of the most boring,pointless movies I have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>The jerky camera movements were also annoying.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>Very nice and relaxing late night viewing.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "62               I'd advise anyone to go and see it.            1\n",
       "68   However, this didn't make up for the fact that...          0\n",
       "603                              Avoid at ALL costs!            0\n",
       "586                        This movie is so awesome!            1\n",
       "192  Though The Wind and the Lion is told largely t...          1\n",
       "..                                                 ...        ...\n",
       "272                      Even the squibs look awful.            0\n",
       "554            Meredith M was better than all right.            1\n",
       "653  One of the most boring,pointless movies I have...          0\n",
       "172   The jerky camera movements were also annoying.            0\n",
       "530       Very nice and relaxing late night viewing.            1\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "x_train=imdb_train['review']\n",
    "y_train=imdb_train['sentiment']\n",
    "\n",
    "#Testing Data\n",
    "x_test=imdb_test['review']\n",
    "y_test=imdb_test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LENGTH OF THE REVIEWS IN TERMS OF NO.OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_lens=[]\n",
    "for sent in imdb_train['review']:\n",
    "    sent_lens.append(len(word_tokenize(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1625"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sent_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FREQUENCY OF REVIEW LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(sent_lens,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, AS WE CAN OBSERVE THAT 95% OF TEXTS ARE OF LENGHTS LESS THAN OR EQUAL TO 40.\n",
    "WILL CONSIDER FIRST 40 WORDS AND IGNORE THE REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting maximum number of words \n",
    "max_len=40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENIZING THE WORD FROM A REVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok=Tokenizer(char_level=False,split=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'the',\n",
       " 2: 'a',\n",
       " 3: 'and',\n",
       " 4: 'of',\n",
       " 5: 'is',\n",
       " 6: 'this',\n",
       " 7: 'it',\n",
       " 8: 'i',\n",
       " 9: 'to',\n",
       " 10: 'was',\n",
       " 11: 'movie',\n",
       " 12: 'in',\n",
       " 13: 'film',\n",
       " 14: 'that',\n",
       " 15: '1',\n",
       " 16: '0',\n",
       " 17: 'but',\n",
       " 18: 'for',\n",
       " 19: 'as',\n",
       " 20: 'with',\n",
       " 21: 'are',\n",
       " 22: 'on',\n",
       " 23: 'not',\n",
       " 24: 'you',\n",
       " 25: 'one',\n",
       " 26: 'very',\n",
       " 27: 'bad',\n",
       " 28: 'just',\n",
       " 29: 'so',\n",
       " 30: 'good',\n",
       " 31: 'all',\n",
       " 32: 'an',\n",
       " 33: \"it's\",\n",
       " 34: 'there',\n",
       " 35: 'be',\n",
       " 36: 'by',\n",
       " 37: 'about',\n",
       " 38: 'at',\n",
       " 39: 'if',\n",
       " 40: 'out',\n",
       " 41: 'great',\n",
       " 42: 'his',\n",
       " 43: 'from',\n",
       " 44: 'like',\n",
       " 45: 'have',\n",
       " 46: 'time',\n",
       " 47: 'were',\n",
       " 48: 'well',\n",
       " 49: 'has',\n",
       " 50: 'even',\n",
       " 51: 'really',\n",
       " 52: 'my',\n",
       " 53: 'or',\n",
       " 54: 'who',\n",
       " 55: 'acting',\n",
       " 56: 'he',\n",
       " 57: 'when',\n",
       " 58: 'most',\n",
       " 59: 'see',\n",
       " 60: 'how',\n",
       " 61: 'more',\n",
       " 62: 'characters',\n",
       " 63: 'would',\n",
       " 64: 'no',\n",
       " 65: 'only',\n",
       " 66: 'ever',\n",
       " 67: 'made',\n",
       " 68: 'also',\n",
       " 69: 'best',\n",
       " 70: '10',\n",
       " 71: 'plot',\n",
       " 72: 'some',\n",
       " 73: 'your',\n",
       " 74: 'do',\n",
       " 75: 'its',\n",
       " 76: 'character',\n",
       " 77: 'real',\n",
       " 78: 'because',\n",
       " 79: 'love',\n",
       " 80: \"didn't\",\n",
       " 81: 'movies',\n",
       " 82: 'can',\n",
       " 83: \"don't\",\n",
       " 84: 'other',\n",
       " 85: 'which',\n",
       " 86: 'they',\n",
       " 87: 'story',\n",
       " 88: 'way',\n",
       " 89: 'films',\n",
       " 90: 'actors',\n",
       " 91: 'think',\n",
       " 92: 'much',\n",
       " 93: 'seen',\n",
       " 94: 'too',\n",
       " 95: 'her',\n",
       " 96: 'me',\n",
       " 97: 'every',\n",
       " 98: 'script',\n",
       " 99: 'watching',\n",
       " 100: 'than',\n",
       " 101: 'had',\n",
       " 102: 'up',\n",
       " 103: 'scenes',\n",
       " 104: 'over',\n",
       " 105: 'wonderful',\n",
       " 106: 'show',\n",
       " 107: 'what',\n",
       " 108: 'could',\n",
       " 109: 'little',\n",
       " 110: 'watch',\n",
       " 111: 'will',\n",
       " 112: 'funny',\n",
       " 113: 'work',\n",
       " 114: 'any',\n",
       " 115: 'worth',\n",
       " 116: 'make',\n",
       " 117: 'here',\n",
       " 118: 'man',\n",
       " 119: 'art',\n",
       " 120: 'music',\n",
       " 121: 'into',\n",
       " 122: 'cast',\n",
       " 123: 'many',\n",
       " 124: 'better',\n",
       " 125: 'screen',\n",
       " 126: 'totally',\n",
       " 127: 'go',\n",
       " 128: 'both',\n",
       " 129: 'their',\n",
       " 130: 'never',\n",
       " 131: 'anyone',\n",
       " 132: 'say',\n",
       " 133: 'look',\n",
       " 134: 'nothing',\n",
       " 135: 'everything',\n",
       " 136: 'after',\n",
       " 137: 'again',\n",
       " 138: 'thought',\n",
       " 139: 'line',\n",
       " 140: 'waste',\n",
       " 141: 'get',\n",
       " 142: 'life',\n",
       " 143: 'excellent',\n",
       " 144: 'dialogue',\n",
       " 145: 'scene',\n",
       " 146: 'still',\n",
       " 147: 'such',\n",
       " 148: 'being',\n",
       " 149: \"doesn't\",\n",
       " 150: 'writing',\n",
       " 151: 'people',\n",
       " 152: 'performance',\n",
       " 153: 'going',\n",
       " 154: 'awful',\n",
       " 155: 'things',\n",
       " 156: 'years',\n",
       " 157: 'right',\n",
       " 158: 'recommend',\n",
       " 159: 'know',\n",
       " 160: 'director',\n",
       " 161: \"i'm\",\n",
       " 162: 'truly',\n",
       " 163: 'off',\n",
       " 164: 'she',\n",
       " 165: 'cinematography',\n",
       " 166: 'saw',\n",
       " 167: 'enough',\n",
       " 168: 'been',\n",
       " 169: 'stupid',\n",
       " 170: 'them',\n",
       " 171: 'liked',\n",
       " 172: 'however',\n",
       " 173: 'though',\n",
       " 174: 'simply',\n",
       " 175: 'give',\n",
       " 176: 'ending',\n",
       " 177: 'thing',\n",
       " 178: 'feeling',\n",
       " 179: 'enjoyed',\n",
       " 180: 'beautiful',\n",
       " 181: \"i've\",\n",
       " 182: 'terrible',\n",
       " 183: \"can't\",\n",
       " 184: 'should',\n",
       " 185: 'am',\n",
       " 186: 'actually',\n",
       " 187: 'lot',\n",
       " 188: 'makes',\n",
       " 189: 'through',\n",
       " 190: 'does',\n",
       " 191: 'game',\n",
       " 192: 'camera',\n",
       " 193: 'worst',\n",
       " 194: 'predictable',\n",
       " 195: 'whole',\n",
       " 196: 'done',\n",
       " 197: \"that's\",\n",
       " 198: 'definitely',\n",
       " 199: 'loved',\n",
       " 200: 'job',\n",
       " 201: 'part',\n",
       " 202: 'pretty',\n",
       " 203: 'quite',\n",
       " 204: 'drama',\n",
       " 205: 'highly',\n",
       " 206: 'black',\n",
       " 207: 'between',\n",
       " 208: 'found',\n",
       " 209: 'play',\n",
       " 210: 'two',\n",
       " 211: 'understand',\n",
       " 212: 'these',\n",
       " 213: 'kind',\n",
       " 214: 'first',\n",
       " 215: 'interesting',\n",
       " 216: 'those',\n",
       " 217: 'find',\n",
       " 218: 'another',\n",
       " 219: 'series',\n",
       " 220: 'kids',\n",
       " 221: 'we',\n",
       " 222: 'written',\n",
       " 223: 'did',\n",
       " 224: 'worse',\n",
       " 225: 'played',\n",
       " 226: 'watched',\n",
       " 227: 'least',\n",
       " 228: 'sucked',\n",
       " 229: 'old',\n",
       " 230: 'actor',\n",
       " 231: 'playing',\n",
       " 232: 'horror',\n",
       " 233: 'seeing',\n",
       " 234: 'got',\n",
       " 235: 'wasted',\n",
       " 236: 'big',\n",
       " 237: 'mostly',\n",
       " 238: 'believe',\n",
       " 239: 'incredible',\n",
       " 240: 'whatever',\n",
       " 241: 'directing',\n",
       " 242: 'casting',\n",
       " 243: 'where',\n",
       " 244: 'hilarious',\n",
       " 245: 'anything',\n",
       " 246: 'top',\n",
       " 247: 'self',\n",
       " 248: 'cool',\n",
       " 249: 'gives',\n",
       " 250: 'gets',\n",
       " 251: 'classic',\n",
       " 252: 'money',\n",
       " 253: 'cheap',\n",
       " 254: 'now',\n",
       " 255: 'piece',\n",
       " 256: 'absolutely',\n",
       " 257: 'tv',\n",
       " 258: 'rent',\n",
       " 259: 'use',\n",
       " 260: 'suspense',\n",
       " 261: 'lacks',\n",
       " 262: 'lines',\n",
       " 263: 'action',\n",
       " 264: 'then',\n",
       " 265: \"wasn't\",\n",
       " 266: 'short',\n",
       " 267: 'together',\n",
       " 268: 'boring',\n",
       " 269: 'white',\n",
       " 270: 'disappointed',\n",
       " 271: 'having',\n",
       " 272: 'style',\n",
       " 273: 'myself',\n",
       " 274: 'oh',\n",
       " 275: 'pathetic',\n",
       " 276: 'long',\n",
       " 277: 'come',\n",
       " 278: 'want',\n",
       " 279: 'probably',\n",
       " 280: 'each',\n",
       " 281: 'john',\n",
       " 282: 'fine',\n",
       " 283: 'memorable',\n",
       " 284: 'avoid',\n",
       " 285: 'face',\n",
       " 286: 'superb',\n",
       " 287: 'cinema',\n",
       " 288: 'yet',\n",
       " 289: 'year',\n",
       " 290: 'joy',\n",
       " 291: 'sound',\n",
       " 292: 'comedy',\n",
       " 293: 'special',\n",
       " 294: 'effects',\n",
       " 295: 'experience',\n",
       " 296: 'recommended',\n",
       " 297: 'throughout',\n",
       " 298: 'minutes',\n",
       " 299: 'clever',\n",
       " 300: 'end',\n",
       " 301: 'period',\n",
       " 302: 'particularly',\n",
       " 303: 'tom',\n",
       " 304: 'take',\n",
       " 305: 'terrific',\n",
       " 306: 'second',\n",
       " 307: 'him',\n",
       " 308: 'fact',\n",
       " 309: 'new',\n",
       " 310: 'talk',\n",
       " 311: 'poor',\n",
       " 312: 'flick',\n",
       " 313: 'used',\n",
       " 314: 'enjoy',\n",
       " 315: 'said',\n",
       " 316: \"i'd\",\n",
       " 317: 'amazing',\n",
       " 318: 'history',\n",
       " 319: 'shot',\n",
       " 320: 'ridiculous',\n",
       " 321: 'far',\n",
       " 322: 'entire',\n",
       " 323: 'slow',\n",
       " 324: 'rather',\n",
       " 325: 'different',\n",
       " 326: 'few',\n",
       " 327: 'works',\n",
       " 328: 'almost',\n",
       " 329: 'budget',\n",
       " 330: 'own',\n",
       " 331: 'half',\n",
       " 332: 'editing',\n",
       " 333: 'especially',\n",
       " 334: 'certainly',\n",
       " 335: 'storyline',\n",
       " 336: 'single',\n",
       " 337: 'soundtrack',\n",
       " 338: 'times',\n",
       " 339: 'sometimes',\n",
       " 340: 'girl',\n",
       " 341: 'production',\n",
       " 342: 'human',\n",
       " 343: \"there's\",\n",
       " 344: 'why',\n",
       " 345: 'put',\n",
       " 346: 'lead',\n",
       " 347: 'mess',\n",
       " 348: 'place',\n",
       " 349: 'mention',\n",
       " 350: 'gave',\n",
       " 351: 'adorable',\n",
       " 352: 'without',\n",
       " 353: 'solid',\n",
       " 354: 'point',\n",
       " 355: 'hope',\n",
       " 356: 'us',\n",
       " 357: 'nice',\n",
       " 358: 'energy',\n",
       " 359: 'small',\n",
       " 360: 'become',\n",
       " 361: 'care',\n",
       " 362: 'annoying',\n",
       " 363: 'mean',\n",
       " 364: 'completely',\n",
       " 365: 'insult',\n",
       " 366: 'theater',\n",
       " 367: 'fails',\n",
       " 368: 'making',\n",
       " 369: 'indeed',\n",
       " 370: 'word',\n",
       " 371: 'cult',\n",
       " 372: 'let',\n",
       " 373: 'before',\n",
       " 374: 'everyone',\n",
       " 375: 'amount',\n",
       " 376: 'something',\n",
       " 377: 'huge',\n",
       " 378: 'pretentious',\n",
       " 379: 'during',\n",
       " 380: 'hard',\n",
       " 381: 'ray',\n",
       " 382: 'hitchcock',\n",
       " 383: 'audience',\n",
       " 384: 'extremely',\n",
       " 385: 'rest',\n",
       " 386: 'full',\n",
       " 387: 'crap',\n",
       " 388: 'depth',\n",
       " 389: 'horrible',\n",
       " 390: 'direction',\n",
       " 391: 'visual',\n",
       " 392: 'bit',\n",
       " 393: 'less',\n",
       " 394: 'performances',\n",
       " 395: 'trying',\n",
       " 396: 'guess',\n",
       " 397: 'lame',\n",
       " 398: 'started',\n",
       " 399: \"couldn't\",\n",
       " 400: 'rating',\n",
       " 401: 'three',\n",
       " 402: 'subtle',\n",
       " 403: 'young',\n",
       " 404: 'often',\n",
       " 405: 'away',\n",
       " 406: 'drago',\n",
       " 407: 'barely',\n",
       " 408: 'premise',\n",
       " 409: 'idea',\n",
       " 410: 'scamp',\n",
       " 411: 'garbage',\n",
       " 412: 'follow',\n",
       " 413: 'non',\n",
       " 414: 'keep',\n",
       " 415: 'song',\n",
       " 416: 'roles',\n",
       " 417: 'mind',\n",
       " 418: 'book',\n",
       " 419: 'mediocre',\n",
       " 420: 'itself',\n",
       " 421: 'pg',\n",
       " 422: 'strong',\n",
       " 423: 'may',\n",
       " 424: \"they're\",\n",
       " 425: 'minute',\n",
       " 426: 'around',\n",
       " 427: 'score',\n",
       " 428: 'since',\n",
       " 429: 'tale',\n",
       " 430: 'greatest',\n",
       " 431: \"won't\",\n",
       " 432: 'spoilers',\n",
       " 433: 'ed',\n",
       " 434: 'looks',\n",
       " 435: 'oscar',\n",
       " 436: 'believable',\n",
       " 437: 'actress',\n",
       " 438: 'perfect',\n",
       " 439: 'role',\n",
       " 440: 'actresses',\n",
       " 441: 'called',\n",
       " 442: 'beyond',\n",
       " 443: 'speak',\n",
       " 444: 'house',\n",
       " 445: 'shows',\n",
       " 446: 'learn',\n",
       " 447: 'embarrassing',\n",
       " 448: 'documentary',\n",
       " 449: 'appearance',\n",
       " 450: 'dvd',\n",
       " 451: \"isn't\",\n",
       " 452: 'james',\n",
       " 453: 'earlier',\n",
       " 454: 'level',\n",
       " 455: 'wish',\n",
       " 456: 'silent',\n",
       " 457: 'screenwriter',\n",
       " 458: 'torture',\n",
       " 459: 'convincing',\n",
       " 460: 'comes',\n",
       " 461: 'tell',\n",
       " 462: 'indulgent',\n",
       " 463: 'songs',\n",
       " 464: 'scared',\n",
       " 465: 'intelligence',\n",
       " 466: 'enjoyable',\n",
       " 467: 'checking',\n",
       " 468: 'looked',\n",
       " 469: 'themselves',\n",
       " 470: 'dance',\n",
       " 471: 'happen',\n",
       " 472: 'reason',\n",
       " 473: 'ranks',\n",
       " 474: 'acted',\n",
       " 475: 'overall',\n",
       " 476: 'plus',\n",
       " 477: 'footage',\n",
       " 478: 'sort',\n",
       " 479: 'conclusion',\n",
       " 480: 'ready',\n",
       " 481: 'unconvincing',\n",
       " 482: 'trash',\n",
       " 483: 'must',\n",
       " 484: 'coming',\n",
       " 485: 'heart',\n",
       " 486: 'while',\n",
       " 487: 'mickey',\n",
       " 488: 'including',\n",
       " 489: 'someone',\n",
       " 490: 'world',\n",
       " 491: 'war',\n",
       " 492: 'remember',\n",
       " 493: 'charles',\n",
       " 494: 'thriller',\n",
       " 495: 'usual',\n",
       " 496: 'living',\n",
       " 497: 'attention',\n",
       " 498: 'bore',\n",
       " 499: 'else',\n",
       " 500: 'dancing',\n",
       " 501: 'might',\n",
       " 502: 'significant',\n",
       " 503: 'aerial',\n",
       " 504: 'imagination',\n",
       " 505: 'came',\n",
       " 506: 'fans',\n",
       " 507: 'note',\n",
       " 508: 'surprisingly',\n",
       " 509: 'felt',\n",
       " 510: 'journey',\n",
       " 511: 'eyes',\n",
       " 512: 'child',\n",
       " 513: 'location',\n",
       " 514: 'thoroughly',\n",
       " 515: 'turn',\n",
       " 516: 'day',\n",
       " 517: 'memories',\n",
       " 518: 'billy',\n",
       " 519: 'possibly',\n",
       " 520: 'trilogy',\n",
       " 521: 'talented',\n",
       " 522: 'directed',\n",
       " 523: 'type',\n",
       " 524: 'low',\n",
       " 525: 'grace',\n",
       " 526: 'produced',\n",
       " 527: 'intelligent',\n",
       " 528: 'dialog',\n",
       " 529: 'decent',\n",
       " 530: 'stories',\n",
       " 531: 'unbelievable',\n",
       " 532: 'free',\n",
       " 533: 'occasionally',\n",
       " 534: 'angel',\n",
       " 535: 'parts',\n",
       " 536: 'gem',\n",
       " 537: 'yes',\n",
       " 538: 'seemed',\n",
       " 539: 'same',\n",
       " 540: 'brilliance',\n",
       " 541: 'close',\n",
       " 542: 'ups',\n",
       " 543: 'seem',\n",
       " 544: 'involved',\n",
       " 545: 'negative',\n",
       " 546: 'lovely',\n",
       " 547: 'generally',\n",
       " 548: 'meaning',\n",
       " 549: 'chemistry',\n",
       " 550: 'head',\n",
       " 551: 'serious',\n",
       " 552: 'brilliant',\n",
       " 553: 'created',\n",
       " 554: 'maybe',\n",
       " 555: 'picture',\n",
       " 556: 'values',\n",
       " 557: 'beginning',\n",
       " 558: 'star',\n",
       " 559: 'moving',\n",
       " 560: 'whatsoever',\n",
       " 561: \"i'll\",\n",
       " 562: 'plays',\n",
       " 563: 'moment',\n",
       " 564: 'emotions',\n",
       " 565: 'scenery',\n",
       " 566: 'original',\n",
       " 567: 'race',\n",
       " 568: 'paul',\n",
       " 569: 'along',\n",
       " 570: 'hours',\n",
       " 571: \"wouldn't\",\n",
       " 572: 'next',\n",
       " 573: 'finally',\n",
       " 574: 'stereotypes',\n",
       " 575: 'shots',\n",
       " 576: 'age',\n",
       " 577: 'spent',\n",
       " 578: 'children',\n",
       " 579: 'fan',\n",
       " 580: 'entertaining',\n",
       " 581: \"you'll\",\n",
       " 582: 'stage',\n",
       " 583: 'glad',\n",
       " 584: 'super',\n",
       " 585: 'hour',\n",
       " 586: 'back',\n",
       " 587: 'portrayal',\n",
       " 588: '\\x96',\n",
       " 589: 'whether',\n",
       " 590: 'graphics',\n",
       " 591: 'massive',\n",
       " 592: 'yeah',\n",
       " 593: '8',\n",
       " 594: 'consider',\n",
       " 595: 'sisters',\n",
       " 596: 'fear',\n",
       " 597: 'leave',\n",
       " 598: 'begin',\n",
       " 599: 'smart',\n",
       " 600: 'ass',\n",
       " 601: 'macbeth',\n",
       " 602: 'blood',\n",
       " 603: 'notable',\n",
       " 604: 'beautifully',\n",
       " 605: 'costumes',\n",
       " 606: 'received',\n",
       " 607: 'deserved',\n",
       " 608: 'awesome',\n",
       " 609: 'bought',\n",
       " 610: 'high',\n",
       " 611: 'photography',\n",
       " 612: 'clichés',\n",
       " 613: 'lazy',\n",
       " 614: 'fast',\n",
       " 615: 'idiot',\n",
       " 616: 'several',\n",
       " 617: 'final',\n",
       " 618: 'brief',\n",
       " 619: 'moral',\n",
       " 620: 'decay',\n",
       " 621: 'forces',\n",
       " 622: 'element',\n",
       " 623: 'popular',\n",
       " 624: 'reactions',\n",
       " 625: 'plenty',\n",
       " 626: 'empty',\n",
       " 627: 'hollow',\n",
       " 628: 'frankly',\n",
       " 629: 'lane',\n",
       " 630: 'disappointment',\n",
       " 631: 'proceedings',\n",
       " 632: 'features',\n",
       " 633: 'released',\n",
       " 634: 'video',\n",
       " 635: 'adaptation',\n",
       " 636: 'below',\n",
       " 637: 'turns',\n",
       " 638: 'obviously',\n",
       " 639: 'front',\n",
       " 640: 'exquisite',\n",
       " 641: 'missed',\n",
       " 642: 'step',\n",
       " 643: 'utterly',\n",
       " 644: 'today',\n",
       " 645: 'particular',\n",
       " 646: 'delivering',\n",
       " 647: 'takes',\n",
       " 648: 'fall',\n",
       " 649: 'overly',\n",
       " 650: 'supposed',\n",
       " 651: 'our',\n",
       " 652: 'offensive',\n",
       " 653: 'cartoon',\n",
       " 654: 'already',\n",
       " 655: 'form',\n",
       " 656: 'american',\n",
       " 657: 'unfunny',\n",
       " 658: 'under',\n",
       " 659: 'stars',\n",
       " 660: 'change',\n",
       " 661: 'crowd',\n",
       " 662: 'pleaser',\n",
       " 663: 'among',\n",
       " 664: 'levels',\n",
       " 665: 'italian',\n",
       " 666: 'reviewer',\n",
       " 667: 'scale',\n",
       " 668: 'course',\n",
       " 669: 'fun',\n",
       " 670: 'goes',\n",
       " 671: 'edge',\n",
       " 672: 'somewhat',\n",
       " 673: 'afraid',\n",
       " 674: 'night',\n",
       " 675: 'predictably',\n",
       " 676: 'early',\n",
       " 677: 'implausible',\n",
       " 678: 'air',\n",
       " 679: 'store',\n",
       " 680: 'began',\n",
       " 681: 'needed',\n",
       " 682: 'seriously',\n",
       " 683: 'wilkinson',\n",
       " 684: 'uplifting',\n",
       " 685: 'seems',\n",
       " 686: 'robert',\n",
       " 687: 'father',\n",
       " 688: 'although',\n",
       " 689: 'material',\n",
       " 690: 'hence',\n",
       " 691: 'machine',\n",
       " 692: 'addition',\n",
       " 693: 'mishima',\n",
       " 694: 'uninteresting',\n",
       " 695: 'chilly',\n",
       " 696: 'working',\n",
       " 697: 'singing',\n",
       " 698: 'etc',\n",
       " 699: 'pieces',\n",
       " 700: 'schrader',\n",
       " 701: 'lousy',\n",
       " 702: 'recently',\n",
       " 703: 'struck',\n",
       " 704: 'contained',\n",
       " 705: 'holes',\n",
       " 706: 'realistic',\n",
       " 707: 'lacked',\n",
       " 708: 'talent',\n",
       " 709: 'chance',\n",
       " 710: 'theme',\n",
       " 711: 'thrilled',\n",
       " 712: 'senses',\n",
       " 713: 'deeply',\n",
       " 714: 'narrative',\n",
       " 715: 'june',\n",
       " 716: 'unfortunately',\n",
       " 717: 'plain',\n",
       " 718: 'considering',\n",
       " 719: 'superbly',\n",
       " 720: 'crafted',\n",
       " 721: 'stunning',\n",
       " 722: 'fx',\n",
       " 723: 'offers',\n",
       " 724: 'parents',\n",
       " 725: 'either',\n",
       " 726: 'mexican',\n",
       " 727: 'matter',\n",
       " 728: 'noir',\n",
       " 729: 'given',\n",
       " 730: 'complex',\n",
       " 731: 'psychological',\n",
       " 732: 'soul',\n",
       " 733: 'water',\n",
       " 734: 'gripping',\n",
       " 735: 'control',\n",
       " 736: 'sure',\n",
       " 737: 'places',\n",
       " 738: 'camerawork',\n",
       " 739: \"weren't\",\n",
       " 740: 'witty',\n",
       " 741: 'above',\n",
       " 742: 'favourite',\n",
       " 743: 'directors',\n",
       " 744: 'french',\n",
       " 745: 'appealing',\n",
       " 746: 'spoiler',\n",
       " 747: 'suffering',\n",
       " 748: 'smile',\n",
       " 749: 'literally',\n",
       " 750: 'told',\n",
       " 751: '25',\n",
       " 752: 'unfolds',\n",
       " 753: 'leaves',\n",
       " 754: 'room',\n",
       " 755: 'contrast',\n",
       " 756: 'sublime',\n",
       " 757: '5',\n",
       " 758: 'poetry',\n",
       " 759: 'delivers',\n",
       " 760: 'bunch',\n",
       " 761: 'overacting',\n",
       " 762: 'space',\n",
       " 763: 'warmth',\n",
       " 764: 'reality',\n",
       " 765: 'volcano',\n",
       " 766: 'los',\n",
       " 767: 'angeles',\n",
       " 768: 'nonsense',\n",
       " 769: 'ability',\n",
       " 770: 'pull',\n",
       " 771: 'issues',\n",
       " 772: 'excellently',\n",
       " 773: 'sci',\n",
       " 774: 'perhaps',\n",
       " 775: 'turned',\n",
       " 776: 'b',\n",
       " 777: 'list',\n",
       " 778: 's',\n",
       " 779: 'girlfriend',\n",
       " 780: 'hated',\n",
       " 781: 'cost',\n",
       " 782: 'mad',\n",
       " 783: '50',\n",
       " 784: 'player',\n",
       " 785: 'loneliness',\n",
       " 786: 'underneath',\n",
       " 787: 'mouse',\n",
       " 788: 'games',\n",
       " 789: 'delight',\n",
       " 790: 'sum',\n",
       " 791: 'fantastic',\n",
       " 792: 'dogs',\n",
       " 793: 'disliked',\n",
       " 794: 'problems',\n",
       " 795: 'explanation',\n",
       " 796: 'natural',\n",
       " 797: 'describe',\n",
       " 798: 'fresh',\n",
       " 799: 'paced',\n",
       " 800: 'entirely',\n",
       " 801: 'bring',\n",
       " 802: 'occupied',\n",
       " 803: 'artist',\n",
       " 804: 'voice',\n",
       " 805: 'ratings',\n",
       " 806: 'jobs',\n",
       " 807: 'main',\n",
       " 808: 'ten',\n",
       " 809: 'charm',\n",
       " 810: 'chick',\n",
       " 811: 'case',\n",
       " 812: 'tension',\n",
       " 813: 'conflict',\n",
       " 814: 'undoubtedly',\n",
       " 815: 'running',\n",
       " 816: 'creates',\n",
       " 817: 'remake',\n",
       " 818: 'friends',\n",
       " 819: 'angles',\n",
       " 820: 'following',\n",
       " 821: 'crazy',\n",
       " 822: 'portraying',\n",
       " 823: 'alexander',\n",
       " 824: 'helps',\n",
       " 825: 'wooden',\n",
       " 826: 'light',\n",
       " 827: 'forget',\n",
       " 828: 'attempts',\n",
       " 829: 'bear',\n",
       " 830: 'thinking',\n",
       " 831: 'god',\n",
       " 832: 'male',\n",
       " 833: 'thoughts',\n",
       " 834: 'terms',\n",
       " 835: 'bold',\n",
       " 836: 'writer',\n",
       " 837: 'appalling',\n",
       " 838: 'family',\n",
       " 839: 'sets',\n",
       " 840: 'composition',\n",
       " 841: 'brian',\n",
       " 842: \"he's\",\n",
       " 843: 'kinda',\n",
       " 844: 'cute',\n",
       " 845: 'question',\n",
       " 846: 'ask',\n",
       " 847: 'terribly',\n",
       " 848: 'jamie',\n",
       " 849: 'twist',\n",
       " 850: 'shed',\n",
       " 851: 'situation',\n",
       " 852: 'aspect',\n",
       " 853: 'reading',\n",
       " 854: 'understated',\n",
       " 855: 'revealing',\n",
       " 856: \"haven't\",\n",
       " 857: 'continuity',\n",
       " 858: 'thrown',\n",
       " 859: 'directorial',\n",
       " 860: 'mother',\n",
       " 861: 'impressed',\n",
       " 862: 'death',\n",
       " 863: 'computer',\n",
       " 864: 'home',\n",
       " 865: 'true',\n",
       " 866: \"90's\",\n",
       " 867: 'cartoons',\n",
       " 868: 'humorous',\n",
       " 869: 'cause',\n",
       " 870: 'ago',\n",
       " 871: 'explain',\n",
       " 872: 'neil',\n",
       " 873: 'balance',\n",
       " 874: 'racism',\n",
       " 875: '20th',\n",
       " 876: 'knew',\n",
       " 877: 'relations',\n",
       " 878: 'last',\n",
       " 879: 'regret',\n",
       " 880: 'quinn',\n",
       " 881: 'noteworthy',\n",
       " 882: 'touching',\n",
       " 883: 'lives',\n",
       " 884: 'set',\n",
       " 885: 'episode',\n",
       " 886: '13',\n",
       " 887: 'example',\n",
       " 888: 'jimmy',\n",
       " 889: 'century',\n",
       " 890: 'surprising',\n",
       " 891: 'sand',\n",
       " 892: 'deserving',\n",
       " 893: 'heaven',\n",
       " 894: 'uses',\n",
       " 895: 'european',\n",
       " 896: 'poorly',\n",
       " 897: 'complete',\n",
       " 898: 'interested',\n",
       " 899: 'start',\n",
       " 900: 'genuine',\n",
       " 901: 'handled',\n",
       " 902: 'despite',\n",
       " 903: 'always',\n",
       " 904: 'balanced',\n",
       " 905: 'perfectly',\n",
       " 906: 'weird',\n",
       " 907: 'racial',\n",
       " 908: 'badly',\n",
       " 909: 'wind',\n",
       " 910: 'lion',\n",
       " 911: 'eye',\n",
       " 912: 'nobody',\n",
       " 913: 'cardboard',\n",
       " 914: 'frightening',\n",
       " 915: 'themes',\n",
       " 916: 'versus',\n",
       " 917: 'courtroom',\n",
       " 918: 'length',\n",
       " 919: 'disappointing',\n",
       " 920: 'freedom',\n",
       " 921: 'words',\n",
       " 922: 'central',\n",
       " 923: 'presents',\n",
       " 924: 'imaginable',\n",
       " 925: 'depicts',\n",
       " 926: 'wonder',\n",
       " 927: 'putting',\n",
       " 928: 'exceptional',\n",
       " 929: 'accused',\n",
       " 930: 'south',\n",
       " 931: 'assistant',\n",
       " 932: 'bored',\n",
       " 933: 'happened',\n",
       " 934: 'wonderfully',\n",
       " 935: 'easy',\n",
       " 936: 'lange',\n",
       " 937: 'duet',\n",
       " 938: 'appreciate',\n",
       " 939: 'quality',\n",
       " 940: 'wayne',\n",
       " 941: 'industry',\n",
       " 942: 'presence',\n",
       " 943: 'genius',\n",
       " 944: 'owned',\n",
       " 945: 'daughter',\n",
       " 946: 'provoking',\n",
       " 947: 'ruthless',\n",
       " 948: 'fat',\n",
       " 949: 'lighting',\n",
       " 950: \"joe's\",\n",
       " 951: 'charming',\n",
       " 952: 'junkyard',\n",
       " 953: 'buy',\n",
       " 954: 'female',\n",
       " 955: 'hill',\n",
       " 956: 'doctor',\n",
       " 957: 'business',\n",
       " 958: 'faux',\n",
       " 959: 'drive',\n",
       " 960: 'pure',\n",
       " 961: 'easily',\n",
       " 962: 'important',\n",
       " 963: 'fit',\n",
       " 964: 'create',\n",
       " 965: 'deserves',\n",
       " 966: 'canada',\n",
       " 967: 'sequel',\n",
       " 968: 'rated',\n",
       " 969: 'joke',\n",
       " 970: 'obvious',\n",
       " 971: 'choice',\n",
       " 972: 'lesser',\n",
       " 973: '2',\n",
       " 974: 'whiny',\n",
       " 975: 'anne',\n",
       " 976: 'honestly',\n",
       " 977: 'unpredictable',\n",
       " 978: \"aren't\",\n",
       " 979: 'fifteen',\n",
       " 980: 'pleased',\n",
       " 981: 'feel',\n",
       " 982: 'instead',\n",
       " 983: 'taking',\n",
       " 984: 'review',\n",
       " 985: 'overdue',\n",
       " 986: 'inspiration',\n",
       " 987: 'overcome',\n",
       " 988: 'rejection',\n",
       " 989: 'shelf',\n",
       " 990: 'captures',\n",
       " 991: 'essence',\n",
       " 992: 'comments',\n",
       " 993: 'wall',\n",
       " 994: 'uncalled',\n",
       " 995: 'helen',\n",
       " 996: 'baxendale',\n",
       " 997: 'credible',\n",
       " 998: 'lady',\n",
       " 999: 'cheerfull',\n",
       " 1000: 'naughty',\n",
       " ...}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A distionary where numeric indices are the keys and the individual words are the values\n",
    "tok.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOCABULARY SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of unique/distinct words in the corpus.\n",
    "\n",
    "The index of the first word in this dictionary is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_index_in_vocab=len(tok.index_word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First Word\n",
    "tok.index_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2688"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of the Vectorized Word\n",
    "last_index_in_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'passion'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last Word\n",
    "tok.index_word[2688]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688\n"
     ]
    }
   ],
   "source": [
    "#Assigning the length of Vectorized word in Variable \n",
    "vocab_size=len(tok.index_word.keys())\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AFTER VECTORIZING, CONVERTING ANY ARBITRARY TEXT TO A SEQUENCE OF INTEGERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56, 5, 2, 613]]\n"
     ]
    }
   ],
   "source": [
    "twt=tok.texts_to_sequences(['He is a lazy person.']) #Words not part of the VOCAB will be Dropped eg:'PERSON'\n",
    "print(twt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERTING EACH REVIEW TO A SEQUENCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERT THE TRAIN DATA\n",
    "sequences_train=tok.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456                There still are good actors around!  \n",
       "231       Oh yeah, and the storyline was pathetic too.  \n",
       "250              My 8/10 score is mostly for the plot.  \n",
       "16     This review is long overdue, since I consider ...\n",
       "490    I can't see how this movie can be an inspirati...\n",
       "                             ...                        \n",
       "534            ) a happy, wonderful, feel good ending!  \n",
       "584    I saw it as a child on TV back in 1973, when i...\n",
       "493    Shot in the Southern California desert using h...\n",
       "527                               Avoid, avoid, avoid!  \n",
       "168    I am so pleased to know such a modern day geni...\n",
       "Name: review, Length: 598, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I can't see how this movie can be an inspiration to anyone to come out or overcome fear and rejection.  \""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[490]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456    1\n",
       "231    0\n",
       "250    1\n",
       "16     1\n",
       "490    0\n",
       "      ..\n",
       "534    1\n",
       "584    1\n",
       "493    1\n",
       "527    0\n",
       "168    1\n",
       "Name: sentiment, Length: 598, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[274, 592, 3, 1, 335, 10, 275, 94]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actual Review Words of the Second Review in the training set\n",
    "sequences_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh', 'yeah', 'and', 'the', 'storyline', 'was', 'pathetic', 'too']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=1\n",
    "review=sequences_train[index]\n",
    "review_words=[]\n",
    "for k in review:\n",
    "    review_words.append((tok.index_word[k]))\n",
    "review_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274-oh\n",
      "592-yeah\n",
      "3-and\n",
      "1-the\n",
      "335-storyline\n",
      "10-was\n",
      "275-pathetic\n",
      "94-too\n"
     ]
    }
   ],
   "source": [
    "for word in review_words:\n",
    "    for key, value in tok.index_word.items():\n",
    "        if value==word:\n",
    "            print('{}-{}'.format(key,value))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAD SEQUENCES TO MAKE THEM THE SAME SIZE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  30,  90, 426],\n",
       "       [  0,   0,   0, ...,  10, 275,  94],\n",
       "       [  0,   0,   0, ...,  18,   1,  71],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  44,  64,  84],\n",
       "       [  0,   0,   0, ..., 284, 284, 284],\n",
       "       [  0,   0,   0, ..., 383,  20, 307]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_matrix_train=sequence.pad_sequences(sequences_train,maxlen=max_len)\n",
    "sequences_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 40)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_matrix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 274 592   3   1\n",
      " 335  10 275  94]\n",
      "\n",
      " Every Input Vector is of Length: \n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "#Check the size of each review, exactly 40 words (hopefully with zero padding at the beginning)\n",
    "print(sequences_matrix_train[1])\n",
    "print('\\n Every Input Vector is of Length: ')\n",
    "print(sequences_matrix_train[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT THE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test=tok.texts_to_sequences(x_test) # Convert to numeric sequence\n",
    "sequences_matrix_test=sequence.pad_sequences(sequences_test,maxlen=max_len) #Pad sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILDING RECURRENT NET WITH LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs=Input(name='inputs',shape=[max_len])\n",
    "    layer=Embedding(input_dim=vocab_size+1,output_dim=500,input_length=max_len,mask_zero=True)(inputs)\n",
    "    layer=LSTM(64)(layer)\n",
    "    layer=Dense(256,name='FC1')(layer)\n",
    "    layer=Activation('relu')(layer)\n",
    "    layer=Dropout(0.5)(layer)\n",
    "    layer=Dense(1,name='out_layer')(layer)\n",
    "    layer=Activation('sigmoid')(layer)\n",
    "    model=Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUSTOM  FUNCTION TO BUILD THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 40)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 40, 500)           1344500   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                144640    \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,506,037\n",
      "Trainable params: 1,506,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=RNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "12/12 [==============================] - 9s 248ms/step - loss: 0.6922 - accuracy: 0.5273 - val_loss: 0.6830 - val_accuracy: 0.5933\n",
      "Epoch 2/70\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.6709 - accuracy: 0.6951 - val_loss: 0.6228 - val_accuracy: 0.7733\n",
      "Epoch 3/70\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.4949 - accuracy: 0.9037 - val_loss: 0.5542 - val_accuracy: 0.7667\n",
      "Epoch 4/70\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.1788 - accuracy: 0.9451 - val_loss: 0.5670 - val_accuracy: 0.7733\n",
      "Epoch 5/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.0552 - accuracy: 0.9916 - val_loss: 0.7261 - val_accuracy: 0.8067\n",
      "Epoch 6/70\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.0196 - accuracy: 0.9960 - val_loss: 0.8946 - val_accuracy: 0.7933\n",
      "Epoch 7/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 1.0343 - val_accuracy: 0.8000\n",
      "Epoch 8/70\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1911 - val_accuracy: 0.7800\n",
      "Epoch 9/70\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3340 - val_accuracy: 0.7800\n",
      "Epoch 10/70\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4509 - val_accuracy: 0.7867\n",
      "Epoch 11/70\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.5479 - val_accuracy: 0.7800\n",
      "Epoch 12/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6565 - val_accuracy: 0.7733\n",
      "Epoch 13/70\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 5.7521e-04 - accuracy: 1.0000 - val_loss: 1.7316 - val_accuracy: 0.7733\n",
      "Epoch 14/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 7.2460e-04 - accuracy: 1.0000 - val_loss: 1.7939 - val_accuracy: 0.7733\n",
      "Epoch 15/70\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 5.6434e-04 - accuracy: 1.0000 - val_loss: 1.8501 - val_accuracy: 0.7733\n",
      "Epoch 16/70\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 4.4007e-04 - accuracy: 1.0000 - val_loss: 1.8976 - val_accuracy: 0.7733\n",
      "Epoch 17/70\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 4.2476e-04 - accuracy: 1.0000 - val_loss: 1.9473 - val_accuracy: 0.7667\n",
      "Epoch 18/70\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 3.4582e-04 - accuracy: 1.0000 - val_loss: 1.9935 - val_accuracy: 0.7600\n",
      "Epoch 19/70\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 2.9862e-04 - accuracy: 1.0000 - val_loss: 2.0375 - val_accuracy: 0.7667\n",
      "Epoch 20/70\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 3.0423e-04 - accuracy: 1.0000 - val_loss: 2.0799 - val_accuracy: 0.7533\n",
      "Epoch 21/70\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 2.4860e-04 - accuracy: 1.0000 - val_loss: 2.1199 - val_accuracy: 0.7533\n",
      "Epoch 22/70\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 2.0537e-04 - accuracy: 1.0000 - val_loss: 2.1613 - val_accuracy: 0.7600\n",
      "Epoch 23/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 2.3097e-04 - accuracy: 1.0000 - val_loss: 2.2063 - val_accuracy: 0.7600\n",
      "Epoch 24/70\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 1.3089e-04 - accuracy: 1.0000 - val_loss: 2.2426 - val_accuracy: 0.7600\n",
      "Epoch 25/70\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 1.2141e-04 - accuracy: 1.0000 - val_loss: 2.2756 - val_accuracy: 0.7600\n",
      "Epoch 26/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 1.7881e-04 - accuracy: 1.0000 - val_loss: 2.3109 - val_accuracy: 0.7600\n",
      "Epoch 27/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 1.0051e-04 - accuracy: 1.0000 - val_loss: 2.3411 - val_accuracy: 0.7600\n",
      "Epoch 28/70\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 1.0327e-04 - accuracy: 1.0000 - val_loss: 2.3664 - val_accuracy: 0.7533\n",
      "Epoch 29/70\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 1.4823e-04 - accuracy: 1.0000 - val_loss: 2.3940 - val_accuracy: 0.7533\n",
      "Epoch 30/70\n",
      "12/12 [==============================] - 1s 97ms/step - loss: 9.7354e-05 - accuracy: 1.0000 - val_loss: 2.4225 - val_accuracy: 0.7533\n",
      "Epoch 31/70\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 1.0751e-04 - accuracy: 1.0000 - val_loss: 2.4534 - val_accuracy: 0.7600\n",
      "Epoch 32/70\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 1.0362e-04 - accuracy: 1.0000 - val_loss: 2.4790 - val_accuracy: 0.7600\n",
      "Epoch 33/70\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 1.0738e-04 - accuracy: 1.0000 - val_loss: 2.5061 - val_accuracy: 0.7667\n",
      "Epoch 34/70\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 8.4338e-05 - accuracy: 1.0000 - val_loss: 2.5306 - val_accuracy: 0.7600\n",
      "Epoch 35/70\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 1.1467e-04 - accuracy: 1.0000 - val_loss: 2.5562 - val_accuracy: 0.7600\n",
      "Epoch 36/70\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 8.1687e-05 - accuracy: 1.0000 - val_loss: 2.5802 - val_accuracy: 0.7600\n",
      "Epoch 37/70\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 5.4979e-05 - accuracy: 1.0000 - val_loss: 2.6049 - val_accuracy: 0.7667\n",
      "Epoch 38/70\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 4.8191e-05 - accuracy: 1.0000 - val_loss: 2.6261 - val_accuracy: 0.7667\n",
      "Epoch 39/70\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 5.0940e-05 - accuracy: 1.0000 - val_loss: 2.6478 - val_accuracy: 0.7667\n",
      "Epoch 40/70\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 3.7314e-05 - accuracy: 1.0000 - val_loss: 2.6669 - val_accuracy: 0.7667\n",
      "Epoch 41/70\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 4.6969e-05 - accuracy: 1.0000 - val_loss: 2.6835 - val_accuracy: 0.7667\n",
      "Epoch 42/70\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 3.7673e-05 - accuracy: 1.0000 - val_loss: 2.7009 - val_accuracy: 0.7667\n",
      "Epoch 43/70\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 4.4407e-05 - accuracy: 1.0000 - val_loss: 2.7185 - val_accuracy: 0.7600\n",
      "Epoch 44/70\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 4.9211e-05 - accuracy: 1.0000 - val_loss: 2.7354 - val_accuracy: 0.7600\n",
      "Epoch 45/70\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 6.7380e-05 - accuracy: 1.0000 - val_loss: 2.7561 - val_accuracy: 0.7600\n",
      "Epoch 46/70\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 3.2233e-05 - accuracy: 1.0000 - val_loss: 2.7755 - val_accuracy: 0.7667\n",
      "Epoch 47/70\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 5.4721e-05 - accuracy: 1.0000 - val_loss: 2.7946 - val_accuracy: 0.7667\n",
      "Epoch 48/70\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 2.7319e-05 - accuracy: 1.0000 - val_loss: 2.8104 - val_accuracy: 0.7667\n",
      "Epoch 49/70\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 3.9710e-05 - accuracy: 1.0000 - val_loss: 2.8285 - val_accuracy: 0.7667\n",
      "Epoch 50/70\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5.1460e-05 - accuracy: 1.0000 - val_loss: 2.8461 - val_accuracy: 0.7667\n",
      "Epoch 51/70\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 3.2574e-05 - accuracy: 1.0000 - val_loss: 2.8632 - val_accuracy: 0.7667\n",
      "Epoch 52/70\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 4.1113e-05 - accuracy: 1.0000 - val_loss: 2.8804 - val_accuracy: 0.7667\n",
      "Epoch 53/70\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 2.5205e-05 - accuracy: 1.0000 - val_loss: 2.8947 - val_accuracy: 0.7667\n",
      "Epoch 54/70\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 4.6910e-05 - accuracy: 1.0000 - val_loss: 2.9099 - val_accuracy: 0.7667\n",
      "Epoch 55/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 6.1069e-05 - accuracy: 1.0000 - val_loss: 2.9314 - val_accuracy: 0.7667\n",
      "Epoch 56/70\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 1.9161e-05 - accuracy: 1.0000 - val_loss: 2.9466 - val_accuracy: 0.7667\n",
      "Epoch 57/70\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 1.8966e-05 - accuracy: 1.0000 - val_loss: 2.9598 - val_accuracy: 0.7600\n",
      "Epoch 58/70\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 2.4926e-05 - accuracy: 1.0000 - val_loss: 2.9735 - val_accuracy: 0.7600\n",
      "Epoch 59/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 3.5646e-05 - accuracy: 1.0000 - val_loss: 2.9909 - val_accuracy: 0.7600\n",
      "Epoch 60/70\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 1.6117e-05 - accuracy: 1.0000 - val_loss: 3.0045 - val_accuracy: 0.7600\n",
      "Epoch 61/70\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 1.8286e-05 - accuracy: 1.0000 - val_loss: 3.0172 - val_accuracy: 0.7600\n",
      "Epoch 62/70\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 2.6983e-05 - accuracy: 1.0000 - val_loss: 3.0331 - val_accuracy: 0.7600\n",
      "Epoch 63/70\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 1.6745e-05 - accuracy: 1.0000 - val_loss: 3.0431 - val_accuracy: 0.7600\n",
      "Epoch 64/70\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 2.0574e-05 - accuracy: 1.0000 - val_loss: 3.0553 - val_accuracy: 0.7600\n",
      "Epoch 65/70\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 2.4301e-05 - accuracy: 1.0000 - val_loss: 3.0686 - val_accuracy: 0.7600\n",
      "Epoch 66/70\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 1.8344e-05 - accuracy: 1.0000 - val_loss: 3.0833 - val_accuracy: 0.7600\n",
      "Epoch 67/70\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5.0902e-05 - accuracy: 1.0000 - val_loss: 3.1018 - val_accuracy: 0.7600\n",
      "Epoch 68/70\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 1.9162e-05 - accuracy: 1.0000 - val_loss: 3.1153 - val_accuracy: 0.7600\n",
      "Epoch 69/70\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 1.7506e-05 - accuracy: 1.0000 - val_loss: 3.1264 - val_accuracy: 0.7600\n",
      "Epoch 70/70\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 2.0840e-05 - accuracy: 1.0000 - val_loss: 3.1397 - val_accuracy: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18f6861e940>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix_train,y_train.values,batch_size=50,epochs=70,validation_data=(sequences_matrix_test,y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00],\n",
       "       [9.49198127e-01],\n",
       "       [7.01496674e-07],\n",
       "       [9.88873422e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.77202738e-10],\n",
       "       [1.00000000e+00],\n",
       "       [9.99976635e-01],\n",
       "       [2.17797759e-11],\n",
       "       [2.69064605e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.26543641e-03],\n",
       "       [9.95256066e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.93494568e-12],\n",
       "       [1.00000000e+00],\n",
       "       [8.01328778e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.44035125e-10],\n",
       "       [2.97551495e-09],\n",
       "       [9.99999523e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999702e-01],\n",
       "       [5.60836377e-10],\n",
       "       [3.12155771e-06],\n",
       "       [1.18617879e-06],\n",
       "       [8.22513103e-01],\n",
       "       [9.99963164e-01],\n",
       "       [2.88290812e-06],\n",
       "       [9.99998808e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.78429890e-04],\n",
       "       [1.00000000e+00],\n",
       "       [2.03464047e-12],\n",
       "       [5.19553556e-09],\n",
       "       [9.86231399e-08],\n",
       "       [1.04717355e-08],\n",
       "       [1.00000000e+00],\n",
       "       [4.74121400e-08],\n",
       "       [1.00000000e+00],\n",
       "       [1.76822801e-09],\n",
       "       [9.10650253e-01],\n",
       "       [8.36923242e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.18616957e-07],\n",
       "       [1.00000000e+00],\n",
       "       [8.84195470e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [5.87592695e-05],\n",
       "       [1.77637549e-12],\n",
       "       [1.21599883e-01],\n",
       "       [9.99999225e-01],\n",
       "       [2.52125983e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.66593921e-08],\n",
       "       [1.00000000e+00],\n",
       "       [9.55836892e-01],\n",
       "       [8.33673239e-01],\n",
       "       [6.57747005e-05],\n",
       "       [1.00000000e+00],\n",
       "       [3.02413372e-11],\n",
       "       [9.99882340e-01],\n",
       "       [9.99993920e-01],\n",
       "       [9.99999166e-01],\n",
       "       [2.27569585e-09],\n",
       "       [9.99999762e-01],\n",
       "       [6.63317144e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.97851670e-01],\n",
       "       [4.41715713e-08],\n",
       "       [4.24565331e-12],\n",
       "       [1.00000000e+00],\n",
       "       [1.17606206e-07],\n",
       "       [9.99997377e-01],\n",
       "       [1.09500135e-11],\n",
       "       [6.37942890e-08],\n",
       "       [1.60840390e-08],\n",
       "       [1.60254240e-02],\n",
       "       [9.99975085e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.08825587e-10],\n",
       "       [1.14410564e-10],\n",
       "       [1.37861122e-07],\n",
       "       [1.02727443e-01],\n",
       "       [5.42390742e-12],\n",
       "       [7.66409158e-09],\n",
       "       [9.99685824e-01],\n",
       "       [8.22923327e-11],\n",
       "       [1.00000000e+00],\n",
       "       [9.99764919e-01],\n",
       "       [1.64210796e-04],\n",
       "       [2.59020329e-02],\n",
       "       [4.99230778e-12],\n",
       "       [1.00000000e+00],\n",
       "       [7.71014762e-12],\n",
       "       [2.77718468e-13],\n",
       "       [1.00000000e+00],\n",
       "       [9.96275842e-01],\n",
       "       [8.71608297e-09],\n",
       "       [1.00000000e+00],\n",
       "       [1.34059787e-03],\n",
       "       [1.03056094e-12],\n",
       "       [1.00000000e+00],\n",
       "       [9.05778348e-01],\n",
       "       [1.53160679e-11],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99997556e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999762e-01],\n",
       "       [8.97964954e-01],\n",
       "       [4.93815060e-05],\n",
       "       [4.81367111e-04],\n",
       "       [4.91625071e-03],\n",
       "       [9.99999881e-01],\n",
       "       [1.00000000e+00],\n",
       "       [7.59934210e-06],\n",
       "       [5.90293098e-07],\n",
       "       [9.99949932e-01],\n",
       "       [9.99999702e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.34568854e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.01111698e-06],\n",
       "       [7.48582706e-12],\n",
       "       [9.97468829e-03],\n",
       "       [9.99998808e-01],\n",
       "       [2.62230635e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.27941319e-10],\n",
       "       [8.02175548e-11],\n",
       "       [3.40393626e-06],\n",
       "       [3.23954828e-06],\n",
       "       [9.04335114e-12],\n",
       "       [7.52616719e-13],\n",
       "       [7.09046754e-12],\n",
       "       [1.35711730e-02],\n",
       "       [9.99942780e-01],\n",
       "       [5.94049692e-04],\n",
       "       [4.35776889e-01],\n",
       "       [3.10039212e-08],\n",
       "       [4.63266542e-06],\n",
       "       [2.63919537e-06],\n",
       "       [3.90228629e-03],\n",
       "       [9.99993563e-01]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(sequences_matrix_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION WITH ROC-AUC SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8084630524244051"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE A PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['however',\n",
       " 'this',\n",
       " \"didn't\",\n",
       " 'make',\n",
       " 'up',\n",
       " 'for',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'overall',\n",
       " 'this',\n",
       " 'was',\n",
       " 'a',\n",
       " 'tremendously',\n",
       " 'boring',\n",
       " 'movie']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a review from the test set (any index number)\n",
    "index=1\n",
    "review=sequences_test[index]\n",
    "review_words=[]\n",
    "for k in review:\n",
    "    review_words.append((tok.index_word[k]))\n",
    "review_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94919825\n"
     ]
    }
   ],
   "source": [
    "model.predict(sequences_matrix_test[index].reshape(1,40))\n",
    "pred = model.predict(sequences_matrix_test[index].reshape(1,40))[0][0]\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
